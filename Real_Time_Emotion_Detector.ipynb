{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f263c8c-799d-4b11-8b42-70e93164a0bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-12T03:04:08.493621Z",
     "iopub.status.busy": "2023-02-12T03:04:08.493237Z",
     "iopub.status.idle": "2023-02-12T03:04:12.699305Z",
     "shell.execute_reply": "2023-02-12T03:04:12.698786Z",
     "shell.execute_reply.started": "2023-02-12T03:04:08.493595Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd  # To play sound in the notebook\n",
    "import pyaudio\n",
    "import matplotlib\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from keras.models import load_model\n",
    "import noisereduce as nr\n",
    "import math, os, sys, time\n",
    "import random\n",
    "from threading import Thread\n",
    "\n",
    "matplotlib.use('Qt5Agg')\n",
    "plt.style.use('dark_background')\n",
    "plt.rc('figure', titlesize=16)\n",
    "plt.rc('axes', labelsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29a3ac86-6f6a-4ad3-8eb4-2e0956ae0ef6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-12T03:04:12.700980Z",
     "iopub.status.busy": "2023-02-12T03:04:12.700709Z",
     "iopub.status.idle": "2023-02-12T03:04:12.725460Z",
     "shell.execute_reply": "2023-02-12T03:04:12.724927Z",
     "shell.execute_reply.started": "2023-02-12T03:04:12.700961Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class emotion_detector:\n",
    "    # ['angry', 'calm', 'disgust', 'fear', 'happy', 'sad', 'surprise']\n",
    "    def __init__(self,\n",
    "                 model_path,\n",
    "                 gender_classifier=None,\n",
    "                 sample_rate=22050,\n",
    "                 threshold=122):\n",
    "        self.MODEL = load_model(model_path)\n",
    "        if gender_classifier != None:\n",
    "            self.GC_MODEL = load_model(gender_classifier)\n",
    "        else:\n",
    "            self.GC_MODEL = False\n",
    "        EMOTIONS = {\n",
    "            0: 'Angry',\n",
    "            1: 'Calm',\n",
    "            2: 'Disgust',\n",
    "            3: 'Fearful',\n",
    "            4: 'Happy',\n",
    "            5: 'Sad',\n",
    "            6: 'Surprised'\n",
    "        }\n",
    "        self.genders = {0: 'Female', 1: 'Male'}\n",
    "        self.ENC = OneHotEncoder()\n",
    "        self.ENC.fit_transform([['Angry'], ['Calm'], ['Disgust'], ['Fearful'],\n",
    "                                ['Happy'], ['Sad'], ['Surprised']])\n",
    "        self.THRESHOLD = threshold\n",
    "        self.FORMAT = pyaudio.paFloat32\n",
    "        self.CHANNELS = 1\n",
    "        self.RATE = sample_rate\n",
    "        self.sr = self.RATE\n",
    "        self.CHUNK = 1024 * 4\n",
    "        self.COLORS = [\n",
    "            'red', 'lightblue', 'peru', 'darkred', 'green', 'yellow',\n",
    "            'lightpink'\n",
    "        ]\n",
    "        self.EMOTION_LIST = list(EMOTIONS.values())\n",
    "        self.emotion = \"Silence\"\n",
    "        self.gender = \"\"\n",
    "        self.predictions = [0, 0, 0, 0, 0, 0, 0]\n",
    "        self.total_predictions = []\n",
    "        self.LENGTH = 121212\n",
    "        self.AUDIO = pyaudio.PyAudio()\n",
    "        self.FRAME_LENGTH = 2048\n",
    "        self.HOP_LENGTH = 512\n",
    "        self.RECORD_SECONDS = 2.6\n",
    "        self.audio = (np.sin(np.pi * np.arange(self.RECORD_SECONDS) * 54 /\n",
    "                             self.sr)).astype(np.float32)\n",
    "\n",
    "        self.SCALER = StandardScaler()\n",
    "        self.FIG, self.AXES = plt.subplots(1,\n",
    "                                           2,\n",
    "                                           figsize=(14, 8),\n",
    "                                           tight_layout=True)\n",
    "        self.FIG.canvas.mpl_connect('close_event', self.stop_stream)\n",
    "        self.stop_flag = False\n",
    "        self.emo_color = {\n",
    "            self.EMOTION_LIST[i]: self.COLORS[i]\n",
    "            for i in range(len(self.EMOTION_LIST))\n",
    "        }\n",
    "        self.emo_color[\"Silence\"] = 'white'\n",
    "\n",
    "    def __analyser(self, frame):\n",
    "        self.AXES[0].clear()\n",
    "        self.AXES[1].clear()\n",
    "\n",
    "        self.AXES[0].set_ylim(0, 1.2)\n",
    "        self.AXES[1].set_ylim(-1, 1)\n",
    "\n",
    "        plt.suptitle(\"\\n\\n\\n\" + self.emotion.capitalize() + \" \" + self.gender,\n",
    "                     va='center',\n",
    "                     fontweight=\"bold\")\n",
    "        self.AXES[0].bar(self.EMOTION_LIST, self.predictions, color=self.COLORS)\n",
    "\n",
    "        librosa.display.waveshow(y=self.audio,\n",
    "                                 sr=self.sr,\n",
    "                                 ax=self.AXES[1],\n",
    "                                 color=self.emo_color[self.emotion])\n",
    "\n",
    "    def __extract_features(self, audio, sr):\n",
    "        rms = []\n",
    "        mfcc = []\n",
    "        mel = []\n",
    "\n",
    "        # Fetch the sample rate.\n",
    "        normalizedsound = librosa.util.normalize(audio)\n",
    "\n",
    "        # Trim silence from the beginning and the end.\n",
    "        trimmed_audio, index = librosa.effects.trim(y=normalizedsound,\n",
    "                                                    top_db=30)\n",
    "\n",
    "        final_audio = np.pad(trimmed_audio,\n",
    "                             (0, self.LENGTH - len(trimmed_audio)), 'constant')\n",
    "        # Noise reduction.\n",
    "        final_audio = nr.reduce_noise(y=final_audio,\n",
    "                                      sr=self.RATE)  #updated 03/03/22\n",
    "\n",
    "        f1 = librosa.feature.rms(\n",
    "            y=final_audio,\n",
    "            frame_length=self.FRAME_LENGTH,\n",
    "            hop_length=self.HOP_LENGTH).T  # Energy - Root Mean Square\n",
    "\n",
    "        f2 = librosa.feature.melspectrogram(y=final_audio,\n",
    "                                            sr=sr,\n",
    "                                            n_fft=self.FRAME_LENGTH,\n",
    "                                            hop_length=self.HOP_LENGTH).T\n",
    "\n",
    "        f3 = librosa.feature.mfcc(y=final_audio,\n",
    "                                  sr=sr,\n",
    "                                  n_mfcc=40,\n",
    "                                  hop_length=self.HOP_LENGTH).T  # MFCC\n",
    "\n",
    "        # Filling the data lists\n",
    "\n",
    "        rms.append(self.SCALER.fit_transform(f1))\n",
    "        mel.append(self.SCALER.fit_transform(f2))\n",
    "        mfcc.append(self.SCALER.fit_transform(f3))\n",
    "\n",
    "        f_rms = np.asarray(rms)\n",
    "        f_mel = np.asarray(mel)\n",
    "        f_mfccs = np.asarray(mfcc)\n",
    "\n",
    "        # Concatenating all features to 'X' variable.\n",
    "        features = np.concatenate((f_rms, f_mel, f_mfccs), axis=2)\n",
    "        return features\n",
    "\n",
    "    def __emotion(self, audio_features):\n",
    "        predictions = self.MODEL.predict(audio_features,\n",
    "                                         use_multiprocessing=True)\n",
    "        # print(predictions)\n",
    "\n",
    "        max_emo = self.ENC.inverse_transform(predictions)\n",
    "        pred_list = list(predictions)\n",
    "        predictions = np.squeeze(np.array(pred_list).tolist(), axis=0)\n",
    "        # print(predictions)\n",
    "\n",
    "        return predictions, max_emo[0][0]\n",
    "\n",
    "    def __gender(self, audio_features):\n",
    "        if not self.GC_MODEL:\n",
    "            return \"\"\n",
    "        else:\n",
    "            predictions = self.GC_MODEL.predict(audio_features,\n",
    "                                                use_multiprocessing=True)\n",
    "            print(predictions)\n",
    "\n",
    "            prediction = int(predictions.round()[0][0])\n",
    "            # predictions = np.squeeze(np.array(pred_list).tolist(), axis=0)\n",
    "            print(prediction)\n",
    "\n",
    "            return self.genders[prediction]\n",
    "\n",
    "    def list_devices(self):\n",
    "        print(\"----------------------record device list---------------------\")\n",
    "        info = self.AUDIO.get_host_api_info_by_index(0)\n",
    "        numdevices = info.get('deviceCount')\n",
    "        for i in range(0, numdevices):\n",
    "            if (self.AUDIO.get_device_info_by_host_api_device_index(\n",
    "                    0, i).get('maxInputChannels')) > 0:\n",
    "                print(\n",
    "                    \"Input Device id \", i, \" - \",\n",
    "                    self.AUDIO.get_device_info_by_host_api_device_index(\n",
    "                        0, i).get('name'))\n",
    "\n",
    "        print(\"-------------------------------------------------------------\")\n",
    "\n",
    "        index = int(input())\n",
    "        return index\n",
    "\n",
    "    def silence(self, audio):\n",
    "        threshold = (sum(audio) / len(audio))\n",
    "        # print(threshold)\n",
    "        return (sum(audio) / len(audio)) < self.THRESHOLD\n",
    "\n",
    "    def __start(self, file=None, device_index=None):\n",
    "        self.total_predictions = []\n",
    "\n",
    "        if file != None:\n",
    "            try:\n",
    "                audio_data, self.sr = librosa.load(file)\n",
    "                ipd.display(ipd.Audio(data=audio_data, rate=self.sr))\n",
    "                n = len(audio_data) / self.LENGTH\n",
    "                if n < 1:\n",
    "                    self.audio = audio_data\n",
    "                    features = self.__extract_features(audio_data, self.sr)\n",
    "                    self.predictions, self.emotion = self.__emotion(features)\n",
    "                    self.gender = self.__gender(features)\n",
    "                    print(self.predictions, self.emotion)\n",
    "\n",
    "                else:\n",
    "                    for i in range(math.floor(n)):\n",
    "                        self.audio = audio_data[self.LENGTH * i:self.LENGTH *\n",
    "                                                (i + 1)]\n",
    "                        features = self.__extract_features(audio, self.sr)\n",
    "                        self.predictions, self.emotion = self.__emotion(\n",
    "                            features)\n",
    "                        self.gender = self.__gender(features)\n",
    "                        self.total_predictions.append(self.predictions)\n",
    "                        print(self.predictions, self.emotion)\n",
    "\n",
    "                    else:\n",
    "                        self.audio = audio_data[self.LENGTH * i:]\n",
    "                        features = self.__extract_features(audio, self.sr)\n",
    "                        self.predictions, self.emotion = self.__emotion(\n",
    "                            features)\n",
    "                        self.gender = self.__gender(features)\n",
    "                        self.total_predictions.append(self.predictions)\n",
    "                        print(self.predictions, self.emotion)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "\n",
    "        else:\n",
    "            if device_index == None:\n",
    "                print(\"Missing Device Index Or File !\")\n",
    "                sys.exit(1)\n",
    "                # index = self.list_devices()\n",
    "            print(\"recording via index \" + str(device_index))\n",
    "\n",
    "            self.STREAM = self.AUDIO.open(format=self.FORMAT,\n",
    "                                          channels=self.CHANNELS,\n",
    "                                          rate=self.RATE,\n",
    "                                          input=True,\n",
    "                                          input_device_index=device_index,\n",
    "                                          frames_per_buffer=self.CHUNK)\n",
    "            self.sr = self.RATE\n",
    "            n = int(self.RATE / self.CHUNK * self.RECORD_SECONDS)\n",
    "            # print(n)\n",
    "            # try:\n",
    "            while not self.stop_flag:\n",
    "                # print(\"recording started\")\n",
    "                Recordframes = []\n",
    "                for i in range(0, n):\n",
    "                    data = self.STREAM.read(self.CHUNK,\n",
    "                                            exception_on_overflow=False)\n",
    "                    Recordframes.append(data)\n",
    "                # print (\"recording stopped\")\n",
    "                # print(len(Recordframes))\n",
    "                self.audio = np.frombuffer(b''.join(Recordframes),\n",
    "                                           dtype=np.float32)\n",
    "                # ipd.display(ipd.Audio(data=self.audio, rate=self.RATE))\n",
    "                # time.sleep(5)\n",
    "                if self.silence(b''.join(Recordframes[-4:])):\n",
    "                    # print(\"Silence Detected !\")\n",
    "                    self.emotion = \"Silence\"\n",
    "                    self.gender = \"\"\n",
    "                    self.predictions = [0, 0, 0, 0, 0, 0, 0]\n",
    "                else:\n",
    "                    features = self.__extract_features(self.audio, self.RATE)\n",
    "                    self.gender = self.__gender(features)\n",
    "                    self.predictions, self.emotion = self.__emotion(features)\n",
    "                    self.total_predictions.append(self.predictions)\n",
    "                    # print(emotion)\n",
    "\n",
    "        print(\"Main Thread Terminated !\")\n",
    "\n",
    "    def start_stream(self, file=None, device_index=None):\n",
    "        print(\"Stream Started !\")\n",
    "        self.main_thread = Thread(target=self.__start,\n",
    "                                  args=(file, device_index))\n",
    "        self.main_thread.start()\n",
    "        self.anim = FuncAnimation(fig=self.FIG,\n",
    "                                  func=self.__analyser,\n",
    "                                  interval=1)\n",
    "        plt.show()\n",
    "        FIG, AXES = plt.subplots(1, 1, figsize=(14, 8), tight_layout=True)\n",
    "        AXES.set_ylim(0, 1.2)\n",
    "        plt.suptitle(\"\\n\\n\\nSummary\", va='center', fontweight=\"bold\")\n",
    "        total_predictions = np.mean(np.array(self.total_predictions).tolist(),\n",
    "                                    axis=0)\n",
    "        print(total_predictions)\n",
    "        AXES.bar(self.EMOTION_LIST, total_predictions, color=self.COLORS)\n",
    "        plt.show()\n",
    "\n",
    "    def stop_stream(self, event=None):\n",
    "        self.stop_flag = True\n",
    "        self.main_thread.join()\n",
    "        self.STREAM.stop_stream()\n",
    "        self.STREAM.close()\n",
    "        self.AUDIO.terminate()\n",
    "        print(\"Stream Stoped !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cf6574-1d1c-4843-975b-d58047b91341",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-12T03:13:38.673178Z",
     "iopub.status.busy": "2023-02-12T03:13:38.672535Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------record device list---------------------\n",
      "Input Device id  0  -  𝓚𝔩𐊖𝔥@ɲ🦁 Microphone\n",
      "Input Device id  1  -  MacBook Pro Microphone\n",
      "Input Device id  3  -  𝓚𝔩𐊖𝔥@ɲ’s AirPods Pro 🦁\n",
      "Input Device id  5  -  Microsoft Teams Audio\n",
      "-------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stream Started !\n",
      "recording via index 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1   HIToolbox                           0x00000001b18d05c8 _ZN15MenuBarInstance22EnsureAutoShowObserverEv + 120\n",
      "2   HIToolbox                           0x00000001b187327c SetMenuBarObscured + 224\n",
      "3   HIToolbox                           0x00000001b1872ee8 _ZN13HIApplication15HandleActivatedEP14OpaqueEventRefhP15OpaqueWindowPtrh + 172\n",
      "4   HIToolbox                           0x00000001b186cfcc _ZN13HIApplication13EventObserverEjP14OpaqueEventRefPv + 296\n",
      "5   HIToolbox                           0x00000001b1833cd0 _NotifyEventLoopObservers + 176\n",
      "6   HIToolbox                           0x00000001b186c96c AcquireEventFromQueue + 432\n",
      "7   HIToolbox                           0x00000001b185bc84 ReceiveNextEventCommon + 320\n",
      "8   HIToolbox                           0x00000001b185bb2c _BlockUntilNextEventMatchingListInModeWithFilter + 72\n",
      "9   AppKit                              0x00000001ab408424 _DPSNextEvent + 632\n",
      "10  AppKit                              0x00000001ab4075b4 -[NSApplication(NSEvent) _nextEventMatchingEventMask:untilDate:inMode:dequeue:] + 728\n",
      "11  AppKit                              0x00000001ab3fb9e4 -[NSApplication run] + 464\n",
      "12  libqcocoa.dylib                     0x000000017eb68bb4 qt_plugin_instance + 142160\n",
      "13  python3.9                           0x0000000100b304a8 cfunction_call + 208\n",
      "14  python3.9                           0x0000000100ae13f4 _PyObject_MakeTpCall + 616\n",
      "15  python3.9                           0x0000000100bd1494 call_function + 668\n",
      "16  python3.9                           0x0000000100bcdbfc _PyEval_EvalFrameDefault + 26332\n",
      "17  python3.9                           0x0000000100ae20d0 function_code_fastcall + 116\n",
      "18  python3.9                           0x0000000100bd13fc call_function + 516\n",
      "19  python3.9                           0x0000000100bcdbfc _PyEval_EvalFrameDefault + 26332\n",
      "20  python3.9                           0x0000000100ae20d0 function_code_fastcall + 116\n",
      "21  python3.9                           0x0000000100bd13fc call_function + 516\n",
      "22  python3.9                           0x0000000100bcdbfc _PyEval_EvalFrameDefault + 26332\n",
      "23  python3.9                           0x0000000100bc6ec8 _PyEval_EvalCode + 2804\n",
      "24  python3.9                           0x0000000100ae2014 _PyFunction_Vectorcall + 220\n",
      "25  python3.9                           0x0000000100ae4ea0 method_vectorcall + 336\n",
      "26  python3.9                           0x0000000100bcdf24 _PyEval_EvalFrameDefault + 27140\n",
      "27  python3.9                           0x0000000100bc6ec8 _PyEval_EvalCode + 2804\n",
      "28  python3.9                           0x0000000100ae2014 _PyFunction_Vectorcall + 220\n",
      "29  python3.9                           0x0000000100bd13fc call_function + 516\n",
      "30  python3.9                           0x0000000100bcdbfc _PyEval_EvalFrameDefault + 26332\n",
      "31  python3.9                           0x0000000100bc6ec8 _PyEval_EvalCode + 2804\n",
      "32  python3.9                           0x0000000100ae2014 _PyFunction_Vectorcall + 220\n",
      "33  python3.9                           0x0000000100ae4df4 method_vectorcall + 164\n",
      "34  python3.9                           0x0000000100bd13fc call_function + 516\n",
      "35  python3.9                           0x0000000100bcdcf4 _PyEval_EvalFrameDefault + 26580\n",
      "36  python3.9                           0x0000000100bc6ec8 _PyEval_EvalCode + 2804\n",
      "37  python3.9                           0x0000000100bc63c8 PyEval_EvalCode + 76\n",
      "38  python3.9                           0x0000000100bc1f70 builtin_exec + 844\n",
      "39  python3.9                           0x0000000100b311c8 cfunction_vectorcall_FASTCALL + 216\n",
      "40  python3.9                           0x0000000100bd13fc call_function + 516\n",
      "41  python3.9                           0x0000000100bcdc78 _PyEval_EvalFrameDefault + 26456\n",
      "42  python3.9                           0x0000000100af7908 gen_send_ex + 300\n",
      "43  python3.9                           0x0000000100bca194 _PyEval_EvalFrameDefault + 11380\n",
      "44  python3.9                           0x0000000100af7908 gen_send_ex + 300\n",
      "45  python3.9                           0x0000000100bca194 _PyEval_EvalFrameDefault + 11380\n",
      "46  python3.9                           0x0000000100af7908 gen_send_ex + 300\n",
      "47  python3.9                           0x0000000100aee3ac method_vectorcall_O + 168\n",
      "48  python3.9                           0x0000000100bd13fc call_function + 516\n",
      "49  python3.9                           0x0000000100bcdbd8 _PyEval_EvalFrameDefault + 26296\n",
      "50  python3.9                           0x0000000100ae20d0 function_code_fastcall + 116\n",
      "51  python3.9                           0x0000000100bd13fc call_function + 516\n",
      "52  python3.9                           0x0000000100bcdc78 _PyEval_EvalFrameDefault + 26456\n",
      "53  python3.9                           0x0000000100ae20d0 function_code_fastcall + 116\n",
      "54  python3.9                           0x0000000100bd13fc call_function + 516\n",
      "55  python3.9                           0x0000000100bcdbd8 _PyEval_EvalFrameDefault + 26296\n",
      "56  python3.9                           0x0000000100bc6ec8 _PyEval_EvalCode + 2804\n",
      "57  python3.9                           0x0000000100ae2014 _PyFunction_Vectorcall + 220\n",
      "58  python3.9                           0x0000000100ae4df4 method_vectorcall + 164\n",
      "59  python3.9                           0x0000000100ae1c20 PyVectorcall_Call + 156\n",
      "60  python3.9                           0x0000000100bcdf24 _PyEval_EvalFrameDefault + 27140\n",
      "61  python3.9                           0x0000000100bc6ec8 _PyEval_EvalCode + 2804\n",
      "62  python3.9                           0x0000000100ae2014 _PyFunction_Vectorcall + 220\n",
      "63  python3.9                           0x0000000100ae4df4 method_vectorcall + 164\n",
      "64  python3.9                           0x0000000100bd13fc call_function + 516\n",
      "65  python3.9                           0x0000000100bcdcf4 _PyEval_EvalFrameDefault + 26580\n",
      "66  python3.9                           0x0000000100af7908 gen_send_ex + 300\n",
      "67  python3.9                           0x0000000100bca194 _PyEval_EvalFrameDefault + 11380\n",
      "68  python3.9                           0x0000000100af7908 gen_send_ex + 300\n",
      "69  python3.9                           0x0000000100bca194 _PyEval_EvalFrameDefault + 11380\n",
      "70  python3.9                           0x0000000100af7908 gen_send_ex + 300\n",
      "71  python3.9                           0x0000000100bca194 _PyEval_EvalFrameDefault + 11380\n",
      "72  python3.9                           0x0000000100af7908 gen_send_ex + 300\n",
      "73  python3.9                           0x0000000100bca194 _PyEval_EvalFrameDefault + 11380\n",
      "74  python3.9                           0x0000000100af7908 gen_send_ex + 300\n",
      "75  _asyncio.cpython-39-darwin.so       0x00000001016481ec task_step + 760\n",
      "76  _asyncio.cpython-39-darwin.so       0x0000000101647d28 TaskWakeupMethWrapper_call + 240\n",
      "77  python3.9                           0x0000000100ae13f4 _PyObject_MakeTpCall + 616\n",
      "78  python3.9                           0x0000000100be5950 context_run + 444\n",
      "79  python3.9                           0x0000000100b31080 cfunction_vectorcall_FASTCALL_KEYWORDS + 136\n",
      "80  python3.9                           0x0000000100bcdf24 _PyEval_EvalFrameDefault + 27140\n",
      "81  python3.9                           0x0000000100ae20d0 function_code_fastcall + 116\n",
      "82  python3.9                           0x0000000100bd13fc call_function + 516\n",
      "83  python3.9                           0x0000000100bcdbd8 _PyEval_EvalFrameDefault + 26296\n",
      "84  python3.9                           0x0000000100ae20d0 function_code_fastcall + 116\n",
      "85  python3.9                           0x0000000100bd13fc call_function + 516\n",
      "86  python3.9                           0x0000000100bcdbd8 _PyEval_EvalFrameDefault + 26296\n",
      "87  python3.9                           0x0000000100ae20d0 function_code_fastcall + 116\n",
      "88  python3.9                           0x0000000100bd13fc call_function + 516\n",
      "89  python3.9                           0x0000000100bcdbd8 _PyEval_EvalFrameDefault + 26296\n",
      "90  python3.9                           0x0000000100ae20d0 function_code_fastcall + 116\n",
      "91  python3.9                           0x0000000100bd13fc call_function + 516\n",
      "92  python3.9                           0x0000000100bcdbd8 _PyEval_EvalFrameDefault + 26296\n",
      "93  python3.9                           0x0000000100ae20d0 function_code_fastcall + 116\n",
      "94  python3.9                           0x0000000100bd13fc call_function + 516\n",
      "95  python3.9                           0x0000000100bcdbd8 _PyEval_EvalFrameDefault + 26296\n",
      "96  python3.9                           0x0000000100bc6ec8 _PyEval_EvalCode + 2804\n",
      "97  python3.9                           0x0000000100ae2014 _PyFunction_Vectorcall + 220\n",
      "98  python3.9                           0x0000000100ae4df4 method_vectorcall + 164\n",
      "99  python3.9                           0x0000000100bd13fc call_function + 516\n",
      "100 python3.9                           0x0000000100bcdbfc _PyEval_EvalFrameDefault + 26332\n",
      "101 python3.9                           0x0000000100bc6ec8 _PyEval_EvalCode + 2804\n",
      "102 python3.9                           0x0000000100bc63c8 PyEval_EvalCode + 76\n",
      "103 python3.9                           0x0000000100bc1f70 builtin_exec + 844\n",
      "104 python3.9                           0x0000000100b311c8 cfunction_vectorcall_FASTCALL + 216\n",
      "105 python3.9                           0x0000000100bd13fc call_function + 516\n",
      "106 python3.9                           0x0000000100bcdc78 _PyEval_EvalFrameDefault + 26456\n",
      "107 python3.9                           0x0000000100bc6ec8 _PyEval_EvalCode + 2804\n",
      "108 python3.9                           0x0000000100ae2014 _PyFunction_Vectorcall + 220\n",
      "109 python3.9                           0x0000000100bd13fc call_function + 516\n",
      "110 python3.9                           0x0000000100bcdc78 _PyEval_EvalFrameDefault + 26456\n",
      "111 python3.9                           0x0000000100bc6ec8 _PyEval_EvalCode + 2804\n",
      "112 python3.9                           0x0000000100ae2014 _PyFunction_Vectorcall + 220\n",
      "113 python3.9                           0x0000000100c40f68 pymain_run_module + 272\n",
      "114 python3.9                           0x0000000100c406a8 Py_RunMain + 1612\n",
      "115 python3.9                           0x0000000100c41a40 pymain_main + 1252\n",
      "116 python3.9                           0x0000000100a947a0 main + 56\n",
      "117 dyld                                0x00000001a7d7fe50 start + 2544\n",
      "2023-02-11 22:13:51.471325: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-11 22:13:51.642727: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-11 22:13:52.154411: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-11 22:13:52.656182: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-11 22:13:53.141010: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main Thread Terminated !\n",
      "Stream Stoped !\n",
      "[4.64442277e-02 8.26811428e-05 1.34867223e-01 5.13873591e-04\n",
      " 5.44627773e-01 2.16947504e-01 5.65167149e-02]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1   HIToolbox                           0x00000001b185b90c _ZN15MenuBarInstance22RemoveAutoShowObserverEv + 44\n",
      "2   HIToolbox                           0x00000001b1873214 SetMenuBarObscured + 120\n",
      "3   HIToolbox                           0x00000001b187a390 _ZN13HIApplication11FrontUILostEv + 44\n",
      "4   HIToolbox                           0x00000001b187304c _ZN13HIApplication15HandleActivatedEP14OpaqueEventRefhP15OpaqueWindowPtrh + 528\n",
      "5   HIToolbox                           0x00000001b186cf70 _ZN13HIApplication13EventObserverEjP14OpaqueEventRefPv + 204\n",
      "6   HIToolbox                           0x00000001b1833cd0 _NotifyEventLoopObservers + 176\n",
      "7   HIToolbox                           0x00000001b186c96c AcquireEventFromQueue + 432\n",
      "8   HIToolbox                           0x00000001b185be0c ReceiveNextEventCommon + 712\n",
      "9   HIToolbox                           0x00000001b185bb2c _BlockUntilNextEventMatchingListInModeWithFilter + 72\n",
      "10  AppKit                              0x00000001ab408424 _DPSNextEvent + 632\n",
      "11  AppKit                              0x00000001ab4075b4 -[NSApplication(NSEvent) _nextEventMatchingEventMask:untilDate:inMode:dequeue:] + 728\n",
      "12  AppKit                              0x00000001ab3fb9e4 -[NSApplication run] + 464\n",
      "13  libqcocoa.dylib                     0x000000017eb68bb4 qt_plugin_instance + 142160\n",
      "14  python3.9                           0x0000000100b304a8 cfunction_call + 208\n",
      "15  python3.9                           0x0000000100ae13f4 _PyObject_MakeTpCall + 616\n",
      "16  python3.9                           0x0000000100bd1494 call_function + 668\n",
      "17  python3.9                           0x0000000100bcdbfc _PyEval_EvalFrameDefault + 26332\n",
      "18  python3.9                           0x0000000100ae20d0 function_code_fastcall + 116\n",
      "19  python3.9                           0x0000000100bd13fc call_function + 516\n",
      "20  python3.9                           0x0000000100bcdbfc _PyEval_EvalFrameDefault + 26332\n",
      "21  python3.9                           0x0000000100ae20d0 function_code_fastcall + 116\n",
      "22  python3.9                           0x0000000100bd13fc call_function + 516\n",
      "23  python3.9                           0x0000000100bcdbfc _PyEval_EvalFrameDefault + 26332\n",
      "24  python3.9                           0x0000000100bc6ec8 _PyEval_EvalCode + 2804\n",
      "25  python3.9                           0x0000000100ae2014 _PyFunction_Vectorcall + 220\n",
      "26  python3.9                           0x0000000100ae4ea0 method_vectorcall + 336\n",
      "27  python3.9                           0x0000000100bcdf24 _PyEval_EvalFrameDefault + 27140\n",
      "28  python3.9                           0x0000000100bc6ec8 _PyEval_EvalCode + 2804\n",
      "29  python3.9                           0x0000000100ae2014 _PyFunction_Vectorcall + 220\n",
      "30  python3.9                           0x0000000100bd13fc call_function + 516\n",
      "31  python3.9                           0x0000000100bcdbfc _PyEval_EvalFrameDefault + 26332\n",
      "32  python3.9                           0x0000000100bc6ec8 _PyEval_EvalCode + 2804\n",
      "33  python3.9                           0x0000000100ae2014 _PyFunction_Vectorcall + 220\n",
      "34  python3.9                           0x0000000100ae4df4 method_vectorcall + 164\n",
      "35  python3.9                           0x0000000100bd13fc call_function + 516\n",
      "36  python3.9                           0x0000000100bcdcf4 _PyEval_EvalFrameDefault + 26580\n",
      "37  python3.9                           0x0000000100bc6ec8 _PyEval_EvalCode + 2804\n",
      "38  python3.9                           0x0000000100bc63c8 PyEval_EvalCode + 76\n",
      "39  python3.9                           0x0000000100bc1f70 builtin_exec + 844\n",
      "40  python3.9                           0x0000000100b311c8 cfunction_vectorcall_FASTCALL + 216\n",
      "41  python3.9                           0x0000000100bd13fc call_function + 516\n",
      "42  python3.9                           0x0000000100bcdc78 _PyEval_EvalFrameDefault + 26456\n",
      "43  python3.9                           0x0000000100af7908 gen_send_ex + 300\n",
      "44  python3.9                           0x0000000100bca194 _PyEval_EvalFrameDefault + 11380\n",
      "45  python3.9                           0x0000000100af7908 gen_send_ex + 300\n",
      "46  python3.9                           0x0000000100bca194 _PyEval_EvalFrameDefault + 11380\n",
      "47  python3.9                           0x0000000100af7908 gen_send_ex + 300\n",
      "48  python3.9                           0x0000000100aee3ac method_vectorcall_O + 168\n",
      "49  python3.9                           0x0000000100bd13fc call_function + 516\n",
      "50  python3.9                           0x0000000100bcdbd8 _PyEval_EvalFrameDefault + 26296\n",
      "51  python3.9                           0x0000000100ae20d0 function_code_fastcall + 116\n",
      "52  python3.9                           0x0000000100bd13fc call_function + 516\n",
      "53  python3.9                           0x0000000100bcdc78 _PyEval_EvalFrameDefault + 26456\n",
      "54  python3.9                           0x0000000100ae20d0 function_code_fastcall + 116\n",
      "55  python3.9                           0x0000000100bd13fc call_function + 516\n",
      "56  python3.9                           0x0000000100bcdbd8 _PyEval_EvalFrameDefault + 26296\n",
      "57  python3.9                           0x0000000100bc6ec8 _PyEval_EvalCode + 2804\n",
      "58  python3.9                           0x0000000100ae2014 _PyFunction_Vectorcall + 220\n",
      "59  python3.9                           0x0000000100ae4df4 method_vectorcall + 164\n",
      "60  python3.9                           0x0000000100ae1c20 PyVectorcall_Call + 156\n",
      "61  python3.9                           0x0000000100bcdf24 _PyEval_EvalFrameDefault + 27140\n",
      "62  python3.9                           0x0000000100bc6ec8 _PyEval_EvalCode + 2804\n",
      "63  python3.9                           0x0000000100ae2014 _PyFunction_Vectorcall + 220\n",
      "64  python3.9                           0x0000000100ae4df4 method_vectorcall + 164\n",
      "65  python3.9                           0x0000000100bd13fc call_function + 516\n",
      "66  python3.9                           0x0000000100bcdcf4 _PyEval_EvalFrameDefault + 26580\n",
      "67  python3.9                           0x0000000100af7908 gen_send_ex + 300\n",
      "68  python3.9                           0x0000000100bca194 _PyEval_EvalFrameDefault + 11380\n",
      "69  python3.9                           0x0000000100af7908 gen_send_ex + 300\n",
      "70  python3.9                           0x0000000100bca194 _PyEval_EvalFrameDefault + 11380\n",
      "71  python3.9                           0x0000000100af7908 gen_send_ex + 300\n",
      "72  python3.9                           0x0000000100bca194 _PyEval_EvalFrameDefault + 11380\n",
      "73  python3.9                           0x0000000100af7908 gen_send_ex + 300\n",
      "74  python3.9                           0x0000000100bca194 _PyEval_EvalFrameDefault + 11380\n",
      "75  python3.9                           0x0000000100af7908 gen_send_ex + 300\n",
      "76  _asyncio.cpython-39-darwin.so       0x00000001016481ec task_step + 760\n",
      "77  _asyncio.cpython-39-darwin.so       0x0000000101647d28 TaskWakeupMethWrapper_call + 240\n",
      "78  python3.9                           0x0000000100ae13f4 _PyObject_MakeTpCall + 616\n",
      "79  python3.9                           0x0000000100be5950 context_run + 444\n",
      "80  python3.9                           0x0000000100b31080 cfunction_vectorcall_FASTCALL_KEYWORDS + 136\n",
      "81  python3.9                           0x0000000100bcdf24 _PyEval_EvalFrameDefault + 27140\n",
      "82  python3.9                           0x0000000100ae20d0 function_code_fastcall + 116\n",
      "83  python3.9                           0x0000000100bd13fc call_function + 516\n",
      "84  python3.9                           0x0000000100bcdbd8 _PyEval_EvalFrameDefault + 26296\n",
      "85  python3.9                           0x0000000100ae20d0 function_code_fastcall + 116\n",
      "86  python3.9                           0x0000000100bd13fc call_function + 516\n",
      "87  python3.9                           0x0000000100bcdbd8 _PyEval_EvalFrameDefault + 26296\n",
      "88  python3.9                           0x0000000100ae20d0 function_code_fastcall + 116\n",
      "89  python3.9                           0x0000000100bd13fc call_function + 516\n",
      "90  python3.9                           0x0000000100bcdbd8 _PyEval_EvalFrameDefault + 26296\n",
      "91  python3.9                           0x0000000100ae20d0 function_code_fastcall + 116\n",
      "92  python3.9                           0x0000000100bd13fc call_function + 516\n",
      "93  python3.9                           0x0000000100bcdbd8 _PyEval_EvalFrameDefault + 26296\n",
      "94  python3.9                           0x0000000100ae20d0 function_code_fastcall + 116\n",
      "95  python3.9                           0x0000000100bd13fc call_function + 516\n",
      "96  python3.9                           0x0000000100bcdbd8 _PyEval_EvalFrameDefault + 26296\n",
      "97  python3.9                           0x0000000100bc6ec8 _PyEval_EvalCode + 2804\n",
      "98  python3.9                           0x0000000100ae2014 _PyFunction_Vectorcall + 220\n",
      "99  python3.9                           0x0000000100ae4df4 method_vectorcall + 164\n",
      "100 python3.9                           0x0000000100bd13fc call_function + 516\n",
      "101 python3.9                           0x0000000100bcdbfc _PyEval_EvalFrameDefault + 26332\n",
      "102 python3.9                           0x0000000100bc6ec8 _PyEval_EvalCode + 2804\n",
      "103 python3.9                           0x0000000100bc63c8 PyEval_EvalCode + 76\n",
      "104 python3.9                           0x0000000100bc1f70 builtin_exec + 844\n",
      "105 python3.9                           0x0000000100b311c8 cfunction_vectorcall_FASTCALL + 216\n",
      "106 python3.9                           0x0000000100bd13fc call_function + 516\n",
      "107 python3.9                           0x0000000100bcdc78 _PyEval_EvalFrameDefault + 26456\n",
      "108 python3.9                           0x0000000100bc6ec8 _PyEval_EvalCode + 2804\n",
      "109 python3.9                           0x0000000100ae2014 _PyFunction_Vectorcall + 220\n",
      "110 python3.9                           0x0000000100bd13fc call_function + 516\n",
      "111 python3.9                           0x0000000100bcdc78 _PyEval_EvalFrameDefault + 26456\n",
      "112 python3.9                           0x0000000100bc6ec8 _PyEval_EvalCode + 2804\n",
      "113 python3.9                           0x0000000100ae2014 _PyFunction_Vectorcall + 220\n",
      "114 python3.9                           0x0000000100c40f68 pymain_run_module + 272\n",
      "115 python3.9                           0x0000000100c406a8 Py_RunMain + 1612\n",
      "116 python3.9                           0x0000000100c41a40 pymain_main + 1252\n",
      "117 python3.9                           0x0000000100a947a0 main + 56\n",
      "118 dyld                                0x00000001a7d7fe50 start + 2544\n"
     ]
    }
   ],
   "source": [
    "# ed = emotion_detector('Models/SER.hdf5', \"Models/Gender_Classifier.hdf5\")\n",
    "ed = emotion_detector('Models/SER.hdf5')\n",
    "device_index = ed.list_devices()\n",
    "ed.start_stream(device_index=device_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e137a88f-b0bc-42bd-86b3-0986e723122a",
   "metadata": {},
   "outputs": [],
   "source": [
    "RAVDESS = \"Data/RAVDESS/audio_speech_actors_01-24/\"\n",
    "TESS = \"Data/TESS/\"\n",
    "datafiles = []\n",
    "for i in os.listdir(TESS):\n",
    "    datafiles.append(TESS + i)\n",
    "\n",
    "for i in os.listdir(RAVDESS):\n",
    "    if os.path.isdir(RAVDESS + i):\n",
    "        for j in os.listdir(RAVDESS + i):\n",
    "            datafiles.append(RAVDESS + i + '/' + j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d140c4be-392f-4e85-b77c-e587c187130f",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = random.choice(datafiles)\n",
    "print(file)\n",
    "ed.start_stream(file=file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618b181b-7d6b-4813-8f33-28c68cf7b638",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fef544-f659-453f-91c8-e3ff443c47ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "autoscrollcelloutput": true,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "0af627a34863016ed57d4b3106c0300251ee54f9e7c94bf74aecdb95dfc7bffc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
